{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a249e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbedbf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to plot gallery\n",
    "def plot_gallery(images,titles,h,w,n_row=3,n_col=4):\n",
    "    \"\"\"plots a gallery of portraits\"\"\"\n",
    "    plt.figure(figsize=(1.8*n_col,2.4*n_row))\n",
    "    plt.subplots_adjust(bottom=0,left=0.1,right=.99,top=.90,hspace=.35)\n",
    "    for i in range(n_row*n_col):\n",
    "        plt.subplot(n_row,n_col,i+1)\n",
    "        plt.imshow(images[i].reshape((h,w)),cmap=plt.cm.gray)\n",
    "        plt.title(titles[i],size=12)\n",
    "        plt.xticks(())\n",
    "        plt.y.ticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9c791ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential #type: ignore\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout #type: ignore\n",
    "from tensorflow.keras.utils import to_categorical #type: ignore\n",
    "# from tensorflow.keras.optimizer import Adam #type: ignore\n",
    "# data set prepration\n",
    "dir_name = r'C:\\Users\\hp\\Desktop\\MODEL\\dataset\\dataset\\faces'\n",
    "h=w=300 #image dimensions\n",
    "y=[] #labels\n",
    "X=[] #features\n",
    "target_names=[] #clss names\n",
    "person_id=0\n",
    "\n",
    "for person_name in os.listdir(dir_name):\n",
    "    dir_path = os.path.join(dir_name, person_name)\n",
    "    for image_name in os.listdir(dir_path):\n",
    "        image_path = os.path.join(dir_path, image_name)\n",
    "        img = cv2.imread(image_path)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        resized_image = cv2.resize(gray, (h, w))\n",
    "        X.append(resized_image.flatten())\n",
    "        y.append(person_id)\n",
    "    target_names.append(person_name)\n",
    "    person_id += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59f8e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(X)\n",
    "y=np.array(y)\n",
    "target_names=np.array(target_names)\n",
    "\n",
    "print(f\"Dataset size: {X.shape},Labels: {y.shape},Classes:{target_names.shape}\")\n",
    "\n",
    "# splitting the data into training and testing sets\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=42)\n",
    "\n",
    "# normalize the data for ANN\n",
    "X_train=X_train/255.0\n",
    "X_test=X_test/255.0\n",
    "\n",
    "# one-hot encode the labels\n",
    "y_train_onehot=to_categorical(y_train)\n",
    "y_test_onehot=to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba50e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN model building\n",
    "model= Sequential([\n",
    "    Flatten(input_shape=(h*w,)),\n",
    "    Dense(512,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(256,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(len(target_names),activation='softmax')\n",
    " ])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
