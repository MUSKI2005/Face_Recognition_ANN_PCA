{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aab69bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the modules \n",
    "import matplotlib.pyplot as plt #type: ignore\n",
    "from sklearn.model_selection import train_test_split #type: ignore\n",
    "from sklearn.datasets import fetch_lfw_people #type: ignore\n",
    "from sklearn.decomposition import PCA #type: ignore\n",
    "import numpy as np \n",
    "import os,cv2\n",
    "def plot_gallery(images,titles,h,w,n_row=3,n_col=4):\n",
    "    \"\"\"helper function to plot a gallery of portraits\"\"\"\n",
    "    plt.figure(figsize=(1.8*n_col,2.4*n_row))\n",
    "    plt.subplots_adjust(bottom=0,left=.01,right=.99,top=.90,hspace=.35)\n",
    "    for i in range(n_row*n_col): #because of the total no. of rows and columns\n",
    "       plt.subplot(n_row,n_col,i+1) #subplot is used to plot multiple plots in a single plot\n",
    " \n",
    "       #i+1 is used to plot the images in the next row\n",
    "       plt.imshow(images[i].reshape((h,w)),cmap=plt.cm.gray)#imshow is used to display the image\n",
    " #reshape is used to reshape the image ,cmap is used to display the image in gray color and plt.cm.gray is used to display the image in gray color\n",
    "       plt.title(titles[i],size=12)#title is used to give the title to the image\n",
    "       plt.xticks(()) #xticks is used to display the x-axis\n",
    "       plt.yticks(()) #yticks is used to display the y-axis\n",
    "\n",
    "#fetch the data\n",
    "dir_name=r'C:\\Users\\hp\\Downloads\\dataset\\dataset\\faces'\n",
    "person_id=0;h=w=300\n",
    "y=[];X=[];target_names=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b839ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_id=0\n",
    "class_names=[]\n",
    "n_samples=0\n",
    "\n",
    "#fetch the data\n",
    "dir_name=r'C:\\Users\\hp\\Downloads\\dataset\\dataset\\faces'\n",
    "for person_name in os.listdir(dir_name):\n",
    "    # formulate the image path\n",
    "    # before we were using this and error was genereating\n",
    "    dir_path = os.path.join(dir_name, person_name)\n",
    "    class_names.append(person_name)\n",
    "    for image_name in os.listdir(dir_path):\n",
    "        # formulate the image path\n",
    "        image_path = os.path.join(dir_path, image_name)\n",
    "        # read the input image\n",
    "        img = cv2.imread(image_path)\n",
    "        # convert into grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        # resize the image to 300x300 dimension\n",
    "        resized_image = cv2.resize(gray, (h, w))\n",
    "        # convert the matrix to vector\n",
    "        v = resized_image.flatten()\n",
    "        X.append(v)\n",
    "        # adding the number of samples\n",
    "        n_samples += 1\n",
    "        # adding the categorical label\n",
    "        y.append(person_id)\n",
    "    # adding the person name\n",
    "    target_names.append(person_name)\n",
    "    # increment the person_id after processing all images of a person\n",
    "    person_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe097de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the list into numpy array\n",
    "y=np.array(y)\n",
    "X=np.array(X)\n",
    "target_names=np.array(target_names)\n",
    "n_features=X.shape[1] #here we are calculating the no. of features in the image\n",
    "print(y.shape,X.shape,target_names.shape)\n",
    "print(\"no. od samples: \",n_samples)\n",
    "n_classes=target_names.shape[0]#shape is used to calculate the no. of rows and columns in the array\n",
    "print(\"Total data set size: \")\n",
    "print(\"n_samples: %d\",n_samples) #%d is used to display the integer value\n",
    "print(\"n_features:%d\",n_features)\n",
    "print(\"n_classes:%d\",n_classes)\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
